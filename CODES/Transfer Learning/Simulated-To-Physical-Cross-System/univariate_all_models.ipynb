{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "34hh7YYS0G00",
    "outputId": "2af10035-5e7f-4591-b730-8bb3f331c1d0"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn import ensemble\n",
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVsYosjT0G1A"
   },
   "outputs": [],
   "source": [
    "def encode_text_features(encode_decode, data_frame, encoder_isa=None, encoder_mem_type=None):\n",
    "    # Implement Categorical OneHot encoding for ISA and mem-type\n",
    "    if encode_decode == 'encode':\n",
    "        encoder_isa = ce.one_hot.OneHotEncoder(cols=['isa'])\n",
    "        encoder_mem_type = ce.one_hot.OneHotEncoder(cols=['mem-type'])\n",
    "        encoder_isa.fit(data_frame, verbose=1)\n",
    "        df_new1 = encoder_isa.transform(data_frame)\n",
    "        encoder_mem_type.fit(df_new1, verbose=1)\n",
    "        df_new = encoder_mem_type.transform(df_new1)\n",
    "        encoded_data_frame = df_new\n",
    "    else:\n",
    "        df_new1 = encoder_isa.transform(data_frame)\n",
    "        df_new = encoder_mem_type.transform(df_new1)\n",
    "        encoded_data_frame = df_new\n",
    "        \n",
    "    return encoded_data_frame, encoder_isa, encoder_mem_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwxxEzWA0G1G"
   },
   "outputs": [],
   "source": [
    "def absolute_percentage_error(Y_test, Y_pred):\n",
    "    error = 0\n",
    "    for i in range(len(Y_test)):\n",
    "        if(Y_test[i]!= 0 ):\n",
    "            error = error + (abs(Y_test[i] - Y_pred[i]))/Y_test[i]\n",
    "        \n",
    "    error = error/ len(Y_test)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_QOjg3qU1eo8"
   },
   "outputs": [],
   "source": [
    "def return_best_param(model, grid, X_train, Y_train):\n",
    "    grid = GridSearchCV(model, grid, refit = True, verbose = 0)\n",
    "    # fitting the model for grid search \n",
    "    tqdm(grid.fit(X_train, Y_train)) \n",
    "    print('Found Best Parameters for this model', model)\n",
    "\n",
    "    # print how our model looks after hyper-parameter tuning \n",
    "    return (grid.best_estimator_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Edkj6tmx0G1M"
   },
   "source": [
    "# Dataset 1 :Qsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "npQlrKff0G1O"
   },
   "outputs": [],
   "source": [
    "def process_all_qsort(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val):\n",
    "    \n",
    "    ################## Data Preprocessing ######################\n",
    "    \n",
    "    df = pd.read_csv(dataset_path + dataset_name + '.csv')\n",
    "    dfn = pd.read_csv(dataset_path + dataset_name_n + '.csv')\n",
    "    encoded_data_frame, encoder_isa, encoder_mem_type = encode_text_features('encode', df\n",
    "                                                                             , encoder_isa = None, encoder_mem_type=None)\n",
    "    encoded_data_frame_n, encoder_isa_n, encoder_mem_type_n = encode_text_features('encode', dfn\n",
    "                                                                                   , encoder_isa = None, encoder_mem_type=None)\n",
    "    \n",
    "    total_data_n = encoded_data_frame_n.drop(columns = ['arch','mem-type_1','mem-type_2','isa_1', 'bus_speed','num-cpu'])\n",
    "    total_data = encoded_data_frame.drop(columns = ['arch','mem-type_1','mem-type_2','mem-type_3','mem-type_4','isa_1',\n",
    "                                                    'isa_2'])\n",
    "    print(total_data.columns, total_data_n.columns, len(total_data.columns), len(total_data_n.columns))\n",
    "    total_data = total_data.fillna(0)\n",
    "    total_data_n = total_data_n.fillna(0)\n",
    " \n",
    "    X_sim = total_data.drop(columns = ['runtime', 'power']).to_numpy()\n",
    "    Y_sim = total_data[val].to_numpy()\n",
    "    X_phy = total_data_n.drop(columns = ['runtime', 'power']).to_numpy()\n",
    "    Y_phy = total_data_n[val].to_numpy()    \n",
    "    print(X_sim.shape, X_phy.shape, Y_sim.shape, Y_phy.shape)\n",
    "\n",
    "    # Separating Physical data to 10% and 90%\n",
    "    X_train_phy, X_test_phy, Y_train_phy, Y_test_phy = train_test_split(X_phy, Y_phy, test_size = 0.90, random_state = 0)\n",
    "    print(X_train_phy.shape, X_test_phy.shape, Y_train_phy.shape, Y_test_phy.shape)\n",
    "    X_train_sim = np.append(X_sim, X_train_phy,axis = 0)\n",
    "    Y_train_sim = np.append(Y_sim, Y_train_phy,axis = 0)\n",
    "    print(X_train_sim.shape, Y_train_sim.shape, X_test_phy.shape, Y_test_phy.shape)\n",
    "    \n",
    "    X_train = X_train_sim\n",
    "    X_test = X_test_phy\n",
    "    Y_train = Y_train_sim\n",
    "    Y_test = Y_test_phy\n",
    "    print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "    \n",
    "    scaler_X_sim = StandardScaler()\n",
    "    scaler_X_phy = StandardScaler()\n",
    "    scaler_X_sim.fit(X_sim)\n",
    "    scaler_X_phy.fit(X_phy)\n",
    "    \n",
    "    scaler_Y_sim = StandardScaler()\n",
    "    scaler_Y_phy = StandardScaler()\n",
    "    Y_sim = np.reshape(Y_sim, (len(Y_sim),1))\n",
    "    Y_phy = np.reshape(Y_phy, (len(Y_phy),1))    \n",
    "    scaler_Y_sim.fit(Y_sim)\n",
    "    scaler_Y_phy.fit(Y_phy)\n",
    "    \n",
    "    X_train = scaler_X_sim.transform(X_train)\n",
    "    X_test = scaler_X_phy.transform(X_test)\n",
    "    Y_train = np.reshape(Y_train, (len(Y_train),1))\n",
    "    Y_test = np.reshape(Y_test, (len(Y_test),1))\n",
    "    Y_train = scaler_Y_sim.transform(Y_train)\n",
    "    Y_test = scaler_Y_phy.fit_transform(Y_test)    \n",
    "    \n",
    "    ################## Data Preprocessing ######################\n",
    "    '''pca = PCA(n_components=9)\n",
    "    pca.fit(X_train)\n",
    "    X_train = pca.transform(X_train)'''\n",
    "\n",
    "    # pca = PCA(n_components=9)\n",
    "    # pca.fit(X_test)\n",
    "    # X_test = pca.transform(X_test)\n",
    "    # Put best models here using grid search\n",
    "    \n",
    "    \n",
    "    # 4. KNN\n",
    "    param_grid_knn =   {'n_neighbors': [ 6, 7, 13, 15],  \n",
    "             'weights' : ['uniform', 'distance'],\n",
    "              'p' : [1, 2, 4, 5, 7 ,10]\n",
    "             } \n",
    "    model_knn = KNeighborsRegressor()          \n",
    "    # best_knn = return_best_param(model_knn, param_grid_knn, X_train, Y_train) \n",
    "    \n",
    "    model_dt = DecisionTreeRegressor()          \n",
    "    # best_dt = return_best_param(model_dt, param_grid_dt, X_train, Y_train) \n",
    "\n",
    "    # 7. Random Forest \n",
    "    param_grid_rf =   {'n_estimators' : [50,  200],  \n",
    "              'max_depth': [5,9,15,20]\n",
    "\n",
    "             } \n",
    "    model_rf = RandomForestRegressor()          \n",
    "    # best_rf = return_best_param(model_rf, param_grid_rf, X_train, Y_train) \n",
    "    \n",
    "    # 8. Extra Trees Regressor\n",
    "    param_grid_etr =   {'n_estimators' : [50, 200],\n",
    "              'max_depth': [5,9,15,20]\n",
    "                       }\n",
    "    model_etr = ExtraTreesRegressor()          \n",
    "    # best_etr =  return_best_param(model_etr, param_grid_etr, X_train, Y_train) \n",
    "    \n",
    "    \n",
    "    # return_best_param(model_xgb, param_grid_xgb, X_train, Y_train)\n",
    "    \n",
    "    # best_models = [best_lr, best_rr, best_knn, best_gpr, best_dt, best_rf, best_etr]\n",
    "    best_models = [model_knn, model_dt, model_rf, model_etr]\n",
    "    best_models_name = [ 'best_knn', 'best_dt', 'best_rf', 'best_etr']\n",
    "    k = 0\n",
    "    \n",
    "    \n",
    "    r2_scores = []\n",
    "    mape_scores = []\n",
    "    for model in best_models:\n",
    "        model_orig = model\n",
    "        print('Running model number:', k+1, 'with Model Name: ', best_models_name[k])\n",
    "        print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "        model_orig.fit(X_train, Y_train)\n",
    "        Y_pred_fold = model_orig.predict(X_test)\n",
    "        Y_test_fold = scaler_Y_phy.inverse_transform(Y_test)\n",
    "        Y_pred_fold = scaler_Y_phy.inverse_transform(Y_pred_fold)\n",
    "\n",
    "        \n",
    "        r2_scores.append(r2_score(Y_test_fold, Y_pred_fold))\n",
    "        mape_scores.append(absolute_percentage_error(Y_test_fold, Y_pred_fold))\n",
    "        \n",
    "\n",
    "        k = k + 1  \n",
    "    return r2_scores, mape_scores\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eV5noIsE0G1U",
    "outputId": "ae8e09a0-e954-4f79-b279-48460b5f7c85",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'PS', 'runtime',\n",
      "       'power'],\n",
      "      dtype='object') Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'PS', 'runtime',\n",
      "       'power'],\n",
      "      dtype='object') 19 19\n",
      "(2730, 17) (672, 17) (2730,) (672,)\n",
      "(67, 17) (605, 17) (67,) (605,)\n",
      "(2797, 17) (2797,) (605, 17) (605,)\n",
      "(2797, 17) (605, 17) (2797,) (605,)\n",
      "Running model number: 1 with Model Name:  best_knn\n",
      "(2797, 17) (605, 17) (2797, 1) (605, 1)\n",
      "Running model number: 2 with Model Name:  best_dt\n",
      "(2797, 17) (605, 17) (2797, 1) (605, 1)\n",
      "Running model number: 3 with Model Name:  best_rf\n",
      "(2797, 17) (605, 17) (2797, 1) (605, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model number: 4 with Model Name:  best_etr\n",
      "(2797, 17) (605, 17) (2797, 1) (605, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'PS', 'runtime',\n",
      "       'power'],\n",
      "      dtype='object') Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'PS', 'runtime',\n",
      "       'power'],\n",
      "      dtype='object') 19 19\n",
      "(2730, 17) (672, 17) (2730,) (672,)\n",
      "(67, 17) (605, 17) (67,) (605,)\n",
      "(2797, 17) (2797,) (605, 17) (605,)\n",
      "(2797, 17) (605, 17) (2797,) (605,)\n",
      "Running model number: 1 with Model Name:  best_knn\n",
      "(2797, 17) (605, 17) (2797, 1) (605, 1)\n",
      "Running model number: 2 with Model Name:  best_dt\n",
      "(2797, 17) (605, 17) (2797, 1) (605, 1)\n",
      "Running model number: 3 with Model Name:  best_rf\n",
      "(2797, 17) (605, 17) (2797, 1) (605, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model number: 4 with Model Name:  best_etr\n",
      "(2797, 17) (605, 17) (2797, 1) (605, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_name        r2  mape_runtime  mape_power\n",
      "0   best_knn  0.202976      0.388767    1.007209\n",
      "1    best_dt -0.187240      0.420365    0.902488\n",
      "2    best_rf -0.226083      0.420755    0.992843\n",
      "3   best_etr  0.355351      0.309951    0.809528\n"
     ]
    }
   ],
   "source": [
    "dataset_name_n = 'qsort_physical'\n",
    "dataset_name = 'qsort_simulated'\n",
    "dataset_path = '\\\\ALL_CSV\\\\Dataset\\\\'\n",
    "path_for_saving_data = dataset_name\n",
    "r2_runtime, mape_runtime = process_all_qsort(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val = 'runtime')                       \n",
    "r2_power, mape_power = process_all_qsort(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val = 'power')                       \n",
    "# print(r2_runtime, r2_power)\n",
    "r2 = []\n",
    "for i in range(4):\n",
    "    r2.append(np.mean([r2_runtime[i], r2_power[i]]))\n",
    "df = pd.DataFrame(columns = ['model_name','r2', 'mape_runtime', 'mape_power'])    \n",
    "\n",
    "best_models_name = [ 'best_knn', 'best_dt', 'best_rf', 'best_etr']\n",
    "for k in range(4):\n",
    "    df = df.append({'model_name': best_models_name[k],\n",
    "                         'r2': r2[k], 'mape_runtime': mape_runtime[k][0],'mape_power': mape_power[k][0]}\n",
    "                       , ignore_index=True)   \n",
    "print(df)    \n",
    "df.to_csv('result_univariate_qsort' + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 2: Dijkstra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nZqqCifDONLp"
   },
   "outputs": [],
   "source": [
    "def process_all_dijkstra(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val):\n",
    "    \n",
    "    ################## Data Preprocessing ######################\n",
    "    \n",
    "    df = pd.read_csv(dataset_path + dataset_name + '.csv')\n",
    "    dfn = pd.read_csv(dataset_path + dataset_name_n + '.csv')\n",
    "    encoded_data_frame, encoder_isa, encoder_mem_type = encode_text_features('encode', df\n",
    "                                                                             , encoder_isa = None, encoder_mem_type=None)\n",
    "    encoded_data_frame_n, encoder_isa_n, encoder_mem_type_n = encode_text_features('encode', dfn\n",
    "                                                                                   , encoder_isa = None, encoder_mem_type=None)\n",
    "    \n",
    "    total_data_n = encoded_data_frame_n.drop(columns = ['arch','mem-type_1','mem-type_2','mem-type_3','mem-type_4',\n",
    "                                                        'isa_1','isa_2' ,'isa_3', 'isa_4', 'bus_speed', 'num-cpu'])\n",
    "    total_data = encoded_data_frame.drop(columns = ['arch','mem-type_1','mem-type_2','mem-type_3','mem-type_4','isa_1',\n",
    "                                                    'isa_2'])\n",
    "    print(total_data.columns, total_data_n.columns, len(total_data.columns), len(total_data_n.columns))\n",
    "    total_data = total_data.fillna(0)\n",
    "    total_data_n = total_data_n.fillna(0)\n",
    " \n",
    "    X_sim = total_data.drop(columns = ['runtime', 'power']).to_numpy()\n",
    "    Y_sim = total_data[val].to_numpy()\n",
    "    X_phy = total_data_n.drop(columns = ['runtime', 'power']).to_numpy()\n",
    "    Y_phy = total_data_n[val].to_numpy()    \n",
    "    print(X_sim.shape, X_phy.shape, Y_sim.shape, Y_phy.shape)\n",
    "\n",
    "    # Separating Physical data to 10% and 90%\n",
    "    X_train_phy, X_test_phy, Y_train_phy, Y_test_phy = train_test_split(X_phy, Y_phy, test_size = 0.90, random_state = 0)\n",
    "    print(X_train_phy.shape, X_test_phy.shape, Y_train_phy.shape, Y_test_phy.shape)\n",
    "    X_train_sim = np.append(X_sim, X_train_phy,axis = 0)\n",
    "    Y_train_sim = np.append(Y_sim, Y_train_phy,axis = 0)\n",
    "    print(X_train_sim.shape, Y_train_sim.shape, X_test_phy.shape, Y_test_phy.shape)\n",
    "    \n",
    "    X_train = X_train_sim\n",
    "    X_test = X_test_phy\n",
    "    Y_train = Y_train_sim\n",
    "    Y_test = Y_test_phy\n",
    "    print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "    \n",
    "    scaler_X_sim = StandardScaler()\n",
    "    scaler_X_phy = StandardScaler()\n",
    "    scaler_X_sim.fit(X_sim)\n",
    "    scaler_X_phy.fit(X_phy)\n",
    "    \n",
    "    scaler_Y_sim = StandardScaler()\n",
    "    scaler_Y_phy = StandardScaler()\n",
    "    Y_sim = np.reshape(Y_sim, (len(Y_sim),1))\n",
    "    Y_phy = np.reshape(Y_phy, (len(Y_phy),1))    \n",
    "    scaler_Y_sim.fit(Y_sim)\n",
    "    scaler_Y_phy.fit(Y_phy)\n",
    "    \n",
    "    X_train = scaler_X_sim.transform(X_train)\n",
    "    X_test = scaler_X_phy.transform(X_test)\n",
    "    Y_train = np.reshape(Y_train, (len(Y_train),1))\n",
    "    Y_test = np.reshape(Y_test, (len(Y_test),1))\n",
    "    Y_train = scaler_Y_sim.transform(Y_train)\n",
    "    Y_test = scaler_Y_phy.fit_transform(Y_test)    \n",
    "    \n",
    "    ################## Data Preprocessing ######################\n",
    "    '''pca = PCA(n_components=9)\n",
    "    pca.fit(X_train)\n",
    "    X_train = pca.transform(X_train)'''\n",
    "\n",
    "    # pca = PCA(n_components=9)\n",
    "    # pca.fit(X_test)\n",
    "    # X_test = pca.transform(X_test)\n",
    "    # Put best models here using grid search\n",
    "    \n",
    "    \n",
    "    # 4. KNN\n",
    "    param_grid_knn =   {'n_neighbors': [ 6, 7, 13, 15],  \n",
    "             'weights' : ['uniform', 'distance'],\n",
    "              'p' : [1, 2, 4, 5, 7 ,10]\n",
    "             } \n",
    "    model_knn = KNeighborsRegressor()          \n",
    "    # best_knn = return_best_param(model_knn, param_grid_knn, X_train, Y_train) \n",
    "    \n",
    "    model_dt = DecisionTreeRegressor()          \n",
    "    # best_dt = return_best_param(model_dt, param_grid_dt, X_train, Y_train) \n",
    "\n",
    "    # 7. Random Forest \n",
    "    param_grid_rf =   {'n_estimators' : [50,  200],  \n",
    "              'max_depth': [5,9,15,20]\n",
    "\n",
    "             } \n",
    "    model_rf = RandomForestRegressor()          \n",
    "    # best_rf = return_best_param(model_rf, param_grid_rf, X_train, Y_train) \n",
    "    \n",
    "    # 8. Extra Trees Regressor\n",
    "    param_grid_etr =   {'n_estimators' : [50, 200],\n",
    "              'max_depth': [5,9,15,20]\n",
    "                       }\n",
    "    model_etr = ExtraTreesRegressor()          \n",
    "    # best_etr =  return_best_param(model_etr, param_grid_etr, X_train, Y_train) \n",
    "    \n",
    "    \n",
    "    # return_best_param(model_xgb, param_grid_xgb, X_train, Y_train)\n",
    "    \n",
    "    # best_models = [best_lr, best_rr, best_knn, best_gpr, best_dt, best_rf, best_etr]\n",
    "    best_models = [model_knn, model_dt, model_rf, model_etr]\n",
    "    best_models_name = [ 'best_knn', 'best_dt', 'best_rf', 'best_etr']\n",
    "    k = 0\n",
    "    \n",
    "    \n",
    "    r2_scores = []\n",
    "    mape_scores = []\n",
    "    for model in best_models:\n",
    "        model_orig = model\n",
    "        print('Running model number:', k+1, 'with Model Name: ', best_models_name[k])\n",
    "        print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "        model_orig.fit(X_train, Y_train)\n",
    "        Y_pred_fold = model_orig.predict(X_test)\n",
    "        Y_test_fold = scaler_Y_phy.inverse_transform(Y_test)\n",
    "        Y_pred_fold = scaler_Y_phy.inverse_transform(Y_pred_fold)\n",
    "\n",
    "        \n",
    "        r2_scores.append(r2_score(Y_test_fold, Y_pred_fold))\n",
    "        mape_scores.append(absolute_percentage_error(Y_test_fold, Y_pred_fold))\n",
    "        \n",
    "\n",
    "        k = k + 1  \n",
    "    return r2_scores, mape_scores\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IMZUd1oKOYvR",
    "outputId": "8cc3551a-5cab-4265-83c1-bd767e0753d2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') 18 18\n",
      "(362, 16) (52, 16) (362,) (52,)\n",
      "(5, 16) (47, 16) (5,) (47,)\n",
      "(367, 16) (367,) (47, 16) (47,)\n",
      "(367, 16) (47, 16) (367,) (47,)\n",
      "Running model number: 1 with Model Name:  best_knn\n",
      "(367, 16) (47, 16) (367, 1) (47, 1)\n",
      "Running model number: 2 with Model Name:  best_dt\n",
      "(367, 16) (47, 16) (367, 1) (47, 1)\n",
      "Running model number: 3 with Model Name:  best_rf\n",
      "(367, 16) (47, 16) (367, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model number: 4 with Model Name:  best_etr\n",
      "(367, 16) (47, 16) (367, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') 18 18\n",
      "(362, 16) (52, 16) (362,) (52,)\n",
      "(5, 16) (47, 16) (5,) (47,)\n",
      "(367, 16) (367,) (47, 16) (47,)\n",
      "(367, 16) (47, 16) (367,) (47,)\n",
      "Running model number: 1 with Model Name:  best_knn\n",
      "(367, 16) (47, 16) (367, 1) (47, 1)\n",
      "Running model number: 2 with Model Name:  best_dt\n",
      "(367, 16) (47, 16) (367, 1) (47, 1)\n",
      "Running model number: 3 with Model Name:  best_rf\n",
      "(367, 16) (47, 16) (367, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model number: 4 with Model Name:  best_etr\n",
      "(367, 16) (47, 16) (367, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_name        r2  mape_runtime  mape_power\n",
      "0   best_knn  0.026137      0.149727    0.568331\n",
      "1    best_dt  0.446164      0.147622    0.177530\n",
      "2    best_rf  0.493021      0.145920    0.167562\n",
      "3   best_etr  0.234186      0.136657    0.378743\n"
     ]
    }
   ],
   "source": [
    "dataset_name_n = 'dijkstra_physical'\n",
    "dataset_name = 'dijkstra_simulated'\n",
    "dataset_path = '\\\\ALL_CSV\\\\Dataset\\\\'\n",
    "path_for_saving_data = dataset_name\n",
    "r2_runtime, mape_runtime = process_all_dijkstra(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val = 'runtime')                       \n",
    "r2_power, mape_power = process_all_dijkstra(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val = 'power')                       \n",
    "# print(r2_runtime, r2_power)\n",
    "r2 = []\n",
    "for i in range(4):\n",
    "    r2.append(np.mean([r2_runtime[i], r2_power[i]]))\n",
    "df = pd.DataFrame(columns = ['model_name','r2', 'mape_runtime', 'mape_power'])    \n",
    "\n",
    "best_models_name = [ 'best_knn', 'best_dt', 'best_rf', 'best_etr']\n",
    "for k in range(4):\n",
    "    df = df.append({'model_name': best_models_name[k],\n",
    "                         'r2': r2[k], 'mape_runtime': mape_runtime[k][0],'mape_power': mape_power[k][0]}\n",
    "                       , ignore_index=True)   \n",
    "print(df)    \n",
    "df.to_csv('result_univariate_dijkstra' + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SSTkvfRcTArg"
   },
   "source": [
    "# Dataset 3: Matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_matmul(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val):\n",
    "    \n",
    "    ################## Data Preprocessing ######################\n",
    "    \n",
    "    df = pd.read_csv(dataset_path + dataset_name + '.csv')\n",
    "    dfn = pd.read_csv(dataset_path + dataset_name_n + '.csv')\n",
    "    encoded_data_frame, encoder_isa, encoder_mem_type = encode_text_features('encode', df\n",
    "                                                                             , encoder_isa = None, encoder_mem_type=None)\n",
    "    encoded_data_frame_n, encoder_isa_n, encoder_mem_type_n = encode_text_features('encode', dfn\n",
    "                                                                                   , encoder_isa = None, encoder_mem_type=None)\n",
    "    \n",
    "    total_data_n = encoded_data_frame_n.drop(columns = ['arch','mem-type_1','mem-type_2','isa_1', 'bus_speed','num-cpu'])\n",
    "    total_data = encoded_data_frame.drop(columns = ['arch','mem-type_1','mem-type_2','mem-type_3','mem-type_4','isa_1',\n",
    "                                                    'isa_2'])\n",
    "    print(total_data.columns, total_data_n.columns, len(total_data.columns), len(total_data_n.columns))\n",
    "    total_data = total_data.fillna(0)\n",
    "    total_data_n = total_data_n.fillna(0)\n",
    " \n",
    "    X_sim = total_data.drop(columns = ['runtime', 'power']).to_numpy()\n",
    "    Y_sim = total_data[val].to_numpy()\n",
    "    X_phy = total_data_n.drop(columns = ['runtime', 'power']).to_numpy()\n",
    "    Y_phy = total_data_n[val].to_numpy()    \n",
    "    print(X_sim.shape, X_phy.shape, Y_sim.shape, Y_phy.shape)\n",
    "\n",
    "    # Separating Physical data to 10% and 90%\n",
    "    X_train_phy, X_test_phy, Y_train_phy, Y_test_phy = train_test_split(X_phy, Y_phy, test_size = 0.90, random_state = 0)\n",
    "    print(X_train_phy.shape, X_test_phy.shape, Y_train_phy.shape, Y_test_phy.shape)\n",
    "    X_train_sim = np.append(X_sim, X_train_phy,axis = 0)\n",
    "    Y_train_sim = np.append(Y_sim, Y_train_phy,axis = 0)\n",
    "    print(X_train_sim.shape, Y_train_sim.shape, X_test_phy.shape, Y_test_phy.shape)\n",
    "    \n",
    "    X_train = X_train_sim\n",
    "    X_test = X_test_phy\n",
    "    Y_train = Y_train_sim\n",
    "    Y_test = Y_test_phy\n",
    "    print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "    \n",
    "    scaler_X_sim = StandardScaler()\n",
    "    scaler_X_phy = StandardScaler()\n",
    "    scaler_X_sim.fit(X_sim)\n",
    "    scaler_X_phy.fit(X_phy)\n",
    "    \n",
    "    scaler_Y_sim = StandardScaler()\n",
    "    scaler_Y_phy = StandardScaler()\n",
    "    Y_sim = np.reshape(Y_sim, (len(Y_sim),1))\n",
    "    Y_phy = np.reshape(Y_phy, (len(Y_phy),1))    \n",
    "    scaler_Y_sim.fit(Y_sim)\n",
    "    scaler_Y_phy.fit(Y_phy)\n",
    "    \n",
    "    X_train = scaler_X_sim.transform(X_train)\n",
    "    X_test = scaler_X_phy.transform(X_test)\n",
    "    Y_train = np.reshape(Y_train, (len(Y_train),1))\n",
    "    Y_test = np.reshape(Y_test, (len(Y_test),1))\n",
    "    Y_train = scaler_Y_sim.transform(Y_train)\n",
    "    Y_test = scaler_Y_phy.fit_transform(Y_test)    \n",
    "    \n",
    "    ################## Data Preprocessing ######################\n",
    "    '''pca = PCA(n_components=9)\n",
    "    pca.fit(X_train)\n",
    "    X_train = pca.transform(X_train)'''\n",
    "\n",
    "    # pca = PCA(n_components=9)\n",
    "    # pca.fit(X_test)\n",
    "    # X_test = pca.transform(X_test)\n",
    "    # Put best models here using grid search\n",
    "    \n",
    "    \n",
    "    # 4. KNN\n",
    "    param_grid_knn =   {'n_neighbors': [ 6, 7, 13, 15],  \n",
    "             'weights' : ['uniform', 'distance'],\n",
    "              'p' : [1, 2, 4, 5, 7 ,10]\n",
    "             } \n",
    "    model_knn = KNeighborsRegressor()          \n",
    "    # best_knn = return_best_param(model_knn, param_grid_knn, X_train, Y_train) \n",
    "    \n",
    "    model_dt = DecisionTreeRegressor()          \n",
    "    # best_dt = return_best_param(model_dt, param_grid_dt, X_train, Y_train) \n",
    "\n",
    "    # 7. Random Forest \n",
    "    param_grid_rf =   {'n_estimators' : [50,  200],  \n",
    "              'max_depth': [5,9,15,20]\n",
    "\n",
    "             } \n",
    "    model_rf = RandomForestRegressor()          \n",
    "    # best_rf = return_best_param(model_rf, param_grid_rf, X_train, Y_train) \n",
    "    \n",
    "    # 8. Extra Trees Regressor\n",
    "    param_grid_etr =   {'n_estimators' : [50, 200],\n",
    "              'max_depth': [5,9,15,20]\n",
    "                       }\n",
    "    model_etr = ExtraTreesRegressor()          \n",
    "    # best_etr =  return_best_param(model_etr, param_grid_etr, X_train, Y_train) \n",
    "    \n",
    "    \n",
    "    # return_best_param(model_xgb, param_grid_xgb, X_train, Y_train)\n",
    "    \n",
    "    # best_models = [best_lr, best_rr, best_knn, best_gpr, best_dt, best_rf, best_etr]\n",
    "    best_models = [model_knn, model_dt, model_rf, model_etr]\n",
    "    best_models_name = [ 'best_knn', 'best_dt', 'best_rf', 'best_etr']\n",
    "    k = 0\n",
    "    \n",
    "    \n",
    "    r2_scores = []\n",
    "    mape_scores = []\n",
    "    for model in best_models:\n",
    "        model_orig = model\n",
    "        print('Running model number:', k+1, 'with Model Name: ', best_models_name[k])\n",
    "        print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "        model_orig.fit(X_train, Y_train)\n",
    "        Y_pred_fold = model_orig.predict(X_test)\n",
    "        Y_test_fold = scaler_Y_phy.inverse_transform(Y_test)\n",
    "        Y_pred_fold = scaler_Y_phy.inverse_transform(Y_pred_fold)\n",
    "\n",
    "        \n",
    "        r2_scores.append(r2_score(Y_test_fold, Y_pred_fold))\n",
    "        mape_scores.append(absolute_percentage_error(Y_test_fold, Y_pred_fold))\n",
    "        \n",
    "\n",
    "        k = k + 1  \n",
    "    return r2_scores, mape_scores\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'PS', 'runtime',\n",
      "       'power'],\n",
      "      dtype='object') Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'PS', 'runtime',\n",
      "       'power'],\n",
      "      dtype='object') 19 19\n",
      "(1780, 17) (519, 17) (1780,) (519,)\n",
      "(51, 17) (468, 17) (51,) (468,)\n",
      "(1831, 17) (1831,) (468, 17) (468,)\n",
      "(1831, 17) (468, 17) (1831,) (468,)\n",
      "Running model number: 1 with Model Name:  best_knn\n",
      "(1831, 17) (468, 17) (1831, 1) (468, 1)\n",
      "Running model number: 2 with Model Name:  best_dt\n",
      "(1831, 17) (468, 17) (1831, 1) (468, 1)\n",
      "Running model number: 3 with Model Name:  best_rf\n",
      "(1831, 17) (468, 17) (1831, 1) (468, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model number: 4 with Model Name:  best_etr\n",
      "(1831, 17) (468, 17) (1831, 1) (468, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'PS', 'runtime',\n",
      "       'power'],\n",
      "      dtype='object') Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'PS', 'runtime',\n",
      "       'power'],\n",
      "      dtype='object') 19 19\n",
      "(1780, 17) (519, 17) (1780,) (519,)\n",
      "(51, 17) (468, 17) (51,) (468,)\n",
      "(1831, 17) (1831,) (468, 17) (468,)\n",
      "(1831, 17) (468, 17) (1831,) (468,)\n",
      "Running model number: 1 with Model Name:  best_knn\n",
      "(1831, 17) (468, 17) (1831, 1) (468, 1)\n",
      "Running model number: 2 with Model Name:  best_dt\n",
      "(1831, 17) (468, 17) (1831, 1) (468, 1)\n",
      "Running model number: 3 with Model Name:  best_rf\n",
      "(1831, 17) (468, 17) (1831, 1) (468, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model number: 4 with Model Name:  best_etr\n",
      "(1831, 17) (468, 17) (1831, 1) (468, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_name        r2  mape_runtime  mape_power\n",
      "0   best_knn  0.043162      1.710582    0.882659\n",
      "1    best_dt -0.248243      1.664266    0.729765\n",
      "2    best_rf -0.233999      1.675748    0.733846\n",
      "3   best_etr  0.099135      1.701964    0.634588\n"
     ]
    }
   ],
   "source": [
    "dataset_name_n = 'matmul_physical'\n",
    "dataset_name = 'matmul_simulated'\n",
    "dataset_path = '\\\\ALL_CSV\\\\Dataset\\\\'\n",
    "path_for_saving_data = dataset_name\n",
    "r2_runtime, mape_runtime = process_all_matmul(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val = 'runtime')                       \n",
    "r2_power, mape_power = process_all_matmul(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val = 'power')                       \n",
    "# print(r2_runtime, r2_power)\n",
    "r2 = []\n",
    "for i in range(4):\n",
    "    r2.append(np.mean([r2_runtime[i], r2_power[i]]))\n",
    "df = pd.DataFrame(columns = ['model_name','r2', 'mape_runtime', 'mape_power'])    \n",
    "\n",
    "best_models_name = [ 'best_knn', 'best_dt', 'best_rf', 'best_etr']\n",
    "for k in range(4):\n",
    "    df = df.append({'model_name': best_models_name[k],\n",
    "                         'r2': r2[k], 'mape_runtime': mape_runtime[k][0],'mape_power': mape_power[k][0]}\n",
    "                       , ignore_index=True)   \n",
    "print(df)    \n",
    "df.to_csv('result_univariate_matmul' + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_tracking(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val):\n",
    "    \n",
    "    ################## Data Preprocessing ######################\n",
    "    \n",
    "    df = pd.read_csv(dataset_path + dataset_name + '.csv')\n",
    "    dfn = pd.read_csv(dataset_path + dataset_name_n + '.csv')\n",
    "    encoded_data_frame, encoder_isa, encoder_mem_type = encode_text_features('encode', df\n",
    "                                                                             , encoder_isa = None, encoder_mem_type=None)\n",
    "    encoded_data_frame_n, encoder_isa_n, encoder_mem_type_n = encode_text_features('encode', dfn\n",
    "                                                                                   , encoder_isa = None, encoder_mem_type=None)\n",
    "    \n",
    "    total_data_n = encoded_data_frame_n.drop(columns = ['arch','mem-type_1','mem-type_2','mem-type_3','mem-type_4',\n",
    "                                                        'isa_1','isa_2' ,'isa_3', 'isa_4', 'bus_speed', 'num-cpu'])\n",
    "    total_data = encoded_data_frame.drop(columns = ['arch','mem-type_1','mem-type_2','mem-type_3','mem-type_4','isa_1',\n",
    "                                                    'isa_2'])\n",
    "    print(total_data.columns, total_data_n.columns, len(total_data.columns), len(total_data_n.columns))\n",
    "    total_data = total_data.fillna(0)\n",
    "    total_data_n = total_data_n.fillna(0)\n",
    " \n",
    "    X_sim = total_data.drop(columns = ['runtime', 'power']).to_numpy()\n",
    "    Y_sim = total_data[val].to_numpy()\n",
    "    X_phy = total_data_n.drop(columns = ['runtime', 'power']).to_numpy()\n",
    "    Y_phy = total_data_n[val].to_numpy()    \n",
    "    print(X_sim.shape, X_phy.shape, Y_sim.shape, Y_phy.shape)\n",
    "\n",
    "    # Separating Physical data to 10% and 90%\n",
    "    X_train_phy, X_test_phy, Y_train_phy, Y_test_phy = train_test_split(X_phy, Y_phy, test_size = 0.90, random_state = 0)\n",
    "    print(X_train_phy.shape, X_test_phy.shape, Y_train_phy.shape, Y_test_phy.shape)\n",
    "    X_train_sim = np.append(X_sim, X_train_phy,axis = 0)\n",
    "    Y_train_sim = np.append(Y_sim, Y_train_phy,axis = 0)\n",
    "    print(X_train_sim.shape, Y_train_sim.shape, X_test_phy.shape, Y_test_phy.shape)\n",
    "    \n",
    "    X_train = X_train_sim\n",
    "    X_test = X_test_phy\n",
    "    Y_train = Y_train_sim\n",
    "    Y_test = Y_test_phy\n",
    "    print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "    \n",
    "    scaler_X_sim = StandardScaler()\n",
    "    scaler_X_phy = StandardScaler()\n",
    "    scaler_X_sim.fit(X_sim)\n",
    "    scaler_X_phy.fit(X_phy)\n",
    "    \n",
    "    scaler_Y_sim = StandardScaler()\n",
    "    scaler_Y_phy = StandardScaler()\n",
    "    Y_sim = np.reshape(Y_sim, (len(Y_sim),1))\n",
    "    Y_phy = np.reshape(Y_phy, (len(Y_phy),1))    \n",
    "    scaler_Y_sim.fit(Y_sim)\n",
    "    scaler_Y_phy.fit(Y_phy)\n",
    "    \n",
    "    X_train = scaler_X_sim.transform(X_train)\n",
    "    X_test = scaler_X_phy.transform(X_test)\n",
    "    Y_train = np.reshape(Y_train, (len(Y_train),1))\n",
    "    Y_test = np.reshape(Y_test, (len(Y_test),1))\n",
    "    Y_train = scaler_Y_sim.transform(Y_train)\n",
    "    Y_test = scaler_Y_phy.fit_transform(Y_test)    \n",
    "    \n",
    "    ################## Data Preprocessing ######################\n",
    "    '''pca = PCA(n_components=9)\n",
    "    pca.fit(X_train)\n",
    "    X_train = pca.transform(X_train)'''\n",
    "\n",
    "    # pca = PCA(n_components=9)\n",
    "    # pca.fit(X_test)\n",
    "    # X_test = pca.transform(X_test)\n",
    "    # Put best models here using grid search\n",
    "    \n",
    "    \n",
    "    # 4. KNN\n",
    "    param_grid_knn =   {'n_neighbors': [ 6, 7, 13, 15],  \n",
    "             'weights' : ['uniform', 'distance'],\n",
    "              'p' : [1, 2, 4, 5, 7 ,10]\n",
    "             } \n",
    "    model_knn = KNeighborsRegressor()          \n",
    "    # best_knn = return_best_param(model_knn, param_grid_knn, X_train, Y_train) \n",
    "    \n",
    "    model_dt = DecisionTreeRegressor()          \n",
    "    # best_dt = return_best_param(model_dt, param_grid_dt, X_train, Y_train) \n",
    "\n",
    "    # 7. Random Forest \n",
    "    param_grid_rf =   {'n_estimators' : [50,  200],  \n",
    "              'max_depth': [5,9,15,20]\n",
    "\n",
    "             } \n",
    "    model_rf = RandomForestRegressor()          \n",
    "    # best_rf = return_best_param(model_rf, param_grid_rf, X_train, Y_train) \n",
    "    \n",
    "    # 8. Extra Trees Regressor\n",
    "    param_grid_etr =   {'n_estimators' : [50, 200],\n",
    "              'max_depth': [5,9,15,20]\n",
    "                       }\n",
    "    model_etr = ExtraTreesRegressor()          \n",
    "    # best_etr =  return_best_param(model_etr, param_grid_etr, X_train, Y_train) \n",
    "    \n",
    "    \n",
    "    # return_best_param(model_xgb, param_grid_xgb, X_train, Y_train)\n",
    "    \n",
    "    # best_models = [best_lr, best_rr, best_knn, best_gpr, best_dt, best_rf, best_etr]\n",
    "    best_models = [model_knn, model_dt, model_rf, model_etr]\n",
    "    best_models_name = [ 'best_knn', 'best_dt', 'best_rf', 'best_etr']\n",
    "    k = 0\n",
    "    \n",
    "    \n",
    "    r2_scores = []\n",
    "    mape_scores = []\n",
    "    for model in best_models:\n",
    "        model_orig = model\n",
    "        print('Running model number:', k+1, 'with Model Name: ', best_models_name[k])\n",
    "        print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "        model_orig.fit(X_train, Y_train)\n",
    "        Y_pred_fold = model_orig.predict(X_test)\n",
    "        Y_test_fold = scaler_Y_phy.inverse_transform(Y_test)\n",
    "        Y_pred_fold = scaler_Y_phy.inverse_transform(Y_pred_fold)\n",
    "\n",
    "        \n",
    "        r2_scores.append(r2_score(Y_test_fold, Y_pred_fold))\n",
    "        mape_scores.append(absolute_percentage_error(Y_test_fold, Y_pred_fold))\n",
    "        \n",
    "\n",
    "        k = k + 1  \n",
    "    return r2_scores, mape_scores\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') 18 18\n",
      "(425, 16) (52, 16) (425,) (52,)\n",
      "(5, 16) (47, 16) (5,) (47,)\n",
      "(430, 16) (430,) (47, 16) (47,)\n",
      "(430, 16) (47, 16) (430,) (47,)\n",
      "Running model number: 1 with Model Name:  best_knn\n",
      "(430, 16) (47, 16) (430, 1) (47, 1)\n",
      "Running model number: 2 with Model Name:  best_dt\n",
      "(430, 16) (47, 16) (430, 1) (47, 1)\n",
      "Running model number: 3 with Model Name:  best_rf\n",
      "(430, 16) (47, 16) (430, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model number: 4 with Model Name:  best_etr\n",
      "(430, 16) (47, 16) (430, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') 18 18\n",
      "(425, 16) (52, 16) (425,) (52,)\n",
      "(5, 16) (47, 16) (5,) (47,)\n",
      "(430, 16) (430,) (47, 16) (47,)\n",
      "(430, 16) (47, 16) (430,) (47,)\n",
      "Running model number: 1 with Model Name:  best_knn\n",
      "(430, 16) (47, 16) (430, 1) (47, 1)\n",
      "Running model number: 2 with Model Name:  best_dt\n",
      "(430, 16) (47, 16) (430, 1) (47, 1)\n",
      "Running model number: 3 with Model Name:  best_rf\n",
      "(430, 16) (47, 16) (430, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model number: 4 with Model Name:  best_etr\n",
      "(430, 16) (47, 16) (430, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_name        r2  mape_runtime  mape_power\n",
      "0   best_knn -0.069951      0.161222    0.621600\n",
      "1    best_dt  0.317745      0.146274    0.502543\n",
      "2    best_rf  0.352084      0.152910    0.452282\n",
      "3   best_etr  0.338626      0.152532    0.423415\n"
     ]
    }
   ],
   "source": [
    "dataset_name_n = 'tracking_physical'\n",
    "dataset_name = 'tracking_simulated'\n",
    "dataset_path = '\\\\ALL_CSV\\\\Dataset\\\\'\n",
    "path_for_saving_data = dataset_name\n",
    "r2_runtime, mape_runtime = process_all_tracking(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val = 'runtime')                       \n",
    "r2_power, mape_power = process_all_tracking(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val = 'power')                       \n",
    "# print(r2_runtime, r2_power)\n",
    "r2 = []\n",
    "for i in range(4):\n",
    "    r2.append(np.mean([r2_runtime[i], r2_power[i]]))\n",
    "df = pd.DataFrame(columns = ['model_name','r2', 'mape_runtime', 'mape_power'])    \n",
    "\n",
    "best_models_name = [ 'best_knn', 'best_dt', 'best_rf', 'best_etr']\n",
    "for k in range(4):\n",
    "    df = df.append({'model_name': best_models_name[k],\n",
    "                         'r2': r2[k], 'mape_runtime': mape_runtime[k][0],'mape_power': mape_power[k][0]}\n",
    "                       , ignore_index=True)   \n",
    "print(df)    \n",
    "df.to_csv('result_univariate_tracking' + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_svm(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val):\n",
    "    \n",
    "    ################## Data Preprocessing ######################\n",
    "    \n",
    "    df = pd.read_csv(dataset_path + dataset_name + '.csv')\n",
    "    dfn = pd.read_csv(dataset_path + dataset_name_n + '.csv')\n",
    "    encoded_data_frame, encoder_isa, encoder_mem_type = encode_text_features('encode', df\n",
    "                                                                             , encoder_isa = None, encoder_mem_type=None)\n",
    "    encoded_data_frame_n, encoder_isa_n, encoder_mem_type_n = encode_text_features('encode', dfn\n",
    "                                                                                   , encoder_isa = None, encoder_mem_type=None)\n",
    "    \n",
    "    total_data_n = encoded_data_frame_n.drop(columns = ['arch','mem-type_1','mem-type_2','mem-type_3','mem-type_4',\n",
    "                                                        'isa_1','isa_2' ,'isa_3', 'isa_4', 'bus_speed', 'num-cpu'])\n",
    "    total_data = encoded_data_frame.drop(columns = ['arch','mem-type_1','mem-type_2','mem-type_3','mem-type_4','isa_1',\n",
    "                                                    'isa_2'])\n",
    "    print(total_data.columns, total_data_n.columns, len(total_data.columns), len(total_data_n.columns))\n",
    "    total_data = total_data.fillna(0)\n",
    "    total_data_n = total_data_n.fillna(0)\n",
    " \n",
    "    X_sim = total_data.drop(columns = ['runtime', 'power']).to_numpy()\n",
    "    Y_sim = total_data[val].to_numpy()\n",
    "    X_phy = total_data_n.drop(columns = ['runtime', 'power']).to_numpy()\n",
    "    Y_phy = total_data_n[val].to_numpy()    \n",
    "    print(X_sim.shape, X_phy.shape, Y_sim.shape, Y_phy.shape)\n",
    "\n",
    "    # Separating Physical data to 10% and 90%\n",
    "    X_train_phy, X_test_phy, Y_train_phy, Y_test_phy = train_test_split(X_phy, Y_phy, test_size = 0.90, random_state = 0)\n",
    "    print(X_train_phy.shape, X_test_phy.shape, Y_train_phy.shape, Y_test_phy.shape)\n",
    "    X_train_sim = np.append(X_sim, X_train_phy,axis = 0)\n",
    "    Y_train_sim = np.append(Y_sim, Y_train_phy,axis = 0)\n",
    "    print(X_train_sim.shape, Y_train_sim.shape, X_test_phy.shape, Y_test_phy.shape)\n",
    "    \n",
    "    X_train = X_train_sim\n",
    "    X_test = X_test_phy\n",
    "    Y_train = Y_train_sim\n",
    "    Y_test = Y_test_phy\n",
    "    print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "    \n",
    "    scaler_X_sim = StandardScaler()\n",
    "    scaler_X_phy = StandardScaler()\n",
    "    scaler_X_sim.fit(X_sim)\n",
    "    scaler_X_phy.fit(X_phy)\n",
    "    \n",
    "    scaler_Y_sim = StandardScaler()\n",
    "    scaler_Y_phy = StandardScaler()\n",
    "    Y_sim = np.reshape(Y_sim, (len(Y_sim),1))\n",
    "    Y_phy = np.reshape(Y_phy, (len(Y_phy),1))    \n",
    "    scaler_Y_sim.fit(Y_sim)\n",
    "    scaler_Y_phy.fit(Y_phy)\n",
    "    \n",
    "    X_train = scaler_X_sim.transform(X_train)\n",
    "    X_test = scaler_X_phy.transform(X_test)\n",
    "    Y_train = np.reshape(Y_train, (len(Y_train),1))\n",
    "    Y_test = np.reshape(Y_test, (len(Y_test),1))\n",
    "    Y_train = scaler_Y_sim.transform(Y_train)\n",
    "    Y_test = scaler_Y_phy.fit_transform(Y_test)    \n",
    "    \n",
    "    ################## Data Preprocessing ######################\n",
    "    '''pca = PCA(n_components=9)\n",
    "    pca.fit(X_train)\n",
    "    X_train = pca.transform(X_train)'''\n",
    "\n",
    "    # pca = PCA(n_components=9)\n",
    "    # pca.fit(X_test)\n",
    "    # X_test = pca.transform(X_test)\n",
    "    # Put best models here using grid search\n",
    "    \n",
    "    \n",
    "    # 4. KNN\n",
    "    param_grid_knn =   {'n_neighbors': [ 6, 7, 13, 15],  \n",
    "             'weights' : ['uniform', 'distance'],\n",
    "              'p' : [1, 2, 4, 5, 7 ,10]\n",
    "             } \n",
    "    model_knn = KNeighborsRegressor()          \n",
    "    # best_knn = return_best_param(model_knn, param_grid_knn, X_train, Y_train) \n",
    "    \n",
    "    model_dt = DecisionTreeRegressor()          \n",
    "    # best_dt = return_best_param(model_dt, param_grid_dt, X_train, Y_train) \n",
    "\n",
    "    # 7. Random Forest \n",
    "    param_grid_rf =   {'n_estimators' : [50,  200],  \n",
    "              'max_depth': [5,9,15,20]\n",
    "\n",
    "             } \n",
    "    model_rf = RandomForestRegressor()          \n",
    "    # best_rf = return_best_param(model_rf, param_grid_rf, X_train, Y_train) \n",
    "    \n",
    "    # 8. Extra Trees Regressor\n",
    "    param_grid_etr =   {'n_estimators' : [50, 200],\n",
    "              'max_depth': [5,9,15,20]\n",
    "                       }\n",
    "    model_etr = ExtraTreesRegressor()          \n",
    "    # best_etr =  return_best_param(model_etr, param_grid_etr, X_train, Y_train) \n",
    "    \n",
    "    \n",
    "    # return_best_param(model_xgb, param_grid_xgb, X_train, Y_train)\n",
    "    \n",
    "    # best_models = [best_lr, best_rr, best_knn, best_gpr, best_dt, best_rf, best_etr]\n",
    "    best_models = [model_knn, model_dt, model_rf, model_etr]\n",
    "    best_models_name = [ 'best_knn', 'best_dt', 'best_rf', 'best_etr']\n",
    "    k = 0\n",
    "    \n",
    "    \n",
    "    r2_scores = []\n",
    "    mape_scores = []\n",
    "    for model in best_models:\n",
    "        model_orig = model\n",
    "        print('Running model number:', k+1, 'with Model Name: ', best_models_name[k])\n",
    "        print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "        model_orig.fit(X_train, Y_train)\n",
    "        Y_pred_fold = model_orig.predict(X_test)\n",
    "        Y_test_fold = scaler_Y_phy.inverse_transform(Y_test)\n",
    "        Y_pred_fold = scaler_Y_phy.inverse_transform(Y_pred_fold)\n",
    "\n",
    "        \n",
    "        r2_scores.append(r2_score(Y_test_fold, Y_pred_fold))\n",
    "        mape_scores.append(absolute_percentage_error(Y_test_fold, Y_pred_fold))\n",
    "        \n",
    "\n",
    "        k = k + 1  \n",
    "    return r2_scores, mape_scores\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') 18 18\n",
      "(390, 16) (52, 16) (390,) (52,)\n",
      "(5, 16) (47, 16) (5,) (47,)\n",
      "(395, 16) (395,) (47, 16) (47,)\n",
      "(395, 16) (47, 16) (395,) (47,)\n",
      "Running model number: 1 with Model Name:  best_knn\n",
      "(395, 16) (47, 16) (395, 1) (47, 1)\n",
      "Running model number: 2 with Model Name:  best_dt\n",
      "(395, 16) (47, 16) (395, 1) (47, 1)\n",
      "Running model number: 3 with Model Name:  best_rf\n",
      "(395, 16) (47, 16) (395, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model number: 4 with Model Name:  best_etr\n",
      "(395, 16) (47, 16) (395, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') 18 18\n",
      "(390, 16) (52, 16) (390,) (52,)\n",
      "(5, 16) (47, 16) (5,) (47,)\n",
      "(395, 16) (395,) (47, 16) (47,)\n",
      "(395, 16) (47, 16) (395,) (47,)\n",
      "Running model number: 1 with Model Name:  best_knn\n",
      "(395, 16) (47, 16) (395, 1) (47, 1)\n",
      "Running model number: 2 with Model Name:  best_dt\n",
      "(395, 16) (47, 16) (395, 1) (47, 1)\n",
      "Running model number: 3 with Model Name:  best_rf\n",
      "(395, 16) (47, 16) (395, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model number: 4 with Model Name:  best_etr\n",
      "(395, 16) (47, 16) (395, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_name        r2  mape_runtime  mape_power\n",
      "0   best_knn -0.522287      0.111705    0.579131\n",
      "1    best_dt  0.051923      0.120993    0.463564\n",
      "2    best_rf  0.173163      0.120499    0.284424\n",
      "3   best_etr  0.027684      0.108803    0.372807\n"
     ]
    }
   ],
   "source": [
    "dataset_name_n = 'svm_physical'\n",
    "dataset_name = 'svm_simulated'\n",
    "dataset_path = '\\\\ALL_CSV\\\\Dataset\\\\'\n",
    "path_for_saving_data = dataset_name\n",
    "r2_runtime, mape_runtime = process_all_svm(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val = 'runtime')                       \n",
    "r2_power, mape_power = process_all_svm(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val = 'power')                       \n",
    "# print(r2_runtime, r2_power)\n",
    "r2 = []\n",
    "for i in range(4):\n",
    "    r2.append(np.mean([r2_runtime[i], r2_power[i]]))\n",
    "df = pd.DataFrame(columns = ['model_name','r2', 'mape_runtime', 'mape_power'])    \n",
    "\n",
    "best_models_name = [ 'best_knn', 'best_dt', 'best_rf', 'best_etr']\n",
    "for k in range(4):\n",
    "    df = df.append({'model_name': best_models_name[k],\n",
    "                         'r2': r2[k], 'mape_runtime': mape_runtime[k][0],'mape_power': mape_power[k][0]}\n",
    "                       , ignore_index=True)   \n",
    "print(df)    \n",
    "df.to_csv('result_univariate_svm' + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montecarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_montecarlo(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val):\n",
    "    \n",
    "    ################## Data Preprocessing ######################\n",
    "    \n",
    "    df = pd.read_csv(dataset_path + dataset_name + '.csv')\n",
    "    dfn = pd.read_csv(dataset_path + dataset_name_n + '.csv')\n",
    "    encoded_data_frame, encoder_isa, encoder_mem_type = encode_text_features('encode', df\n",
    "                                                                             , encoder_isa = None, encoder_mem_type=None)\n",
    "    encoded_data_frame_n, encoder_isa_n, encoder_mem_type_n = encode_text_features('encode', dfn\n",
    "                                                                                   , encoder_isa = None, encoder_mem_type=None)\n",
    "    \n",
    "    total_data_n = encoded_data_frame_n.drop(columns = ['arch','mem-type_1','mem-type_2','isa_1', 'bus_speed','num-cpu'])\n",
    "    total_data = encoded_data_frame.drop(columns = ['arch','mem-type_1','mem-type_2','mem-type_3','mem-type_4','isa_1',\n",
    "                                                    'isa_2'])\n",
    "    print(total_data.columns, total_data_n.columns, len(total_data.columns), len(total_data_n.columns))\n",
    "    total_data = total_data.fillna(0)\n",
    "    total_data_n = total_data_n.fillna(0)\n",
    " \n",
    "    X_sim = total_data.drop(columns = ['runtime', 'power']).to_numpy()\n",
    "    Y_sim = total_data[val].to_numpy()\n",
    "    X_phy = total_data_n.drop(columns = ['runtime', 'power']).to_numpy()\n",
    "    Y_phy = total_data_n[val].to_numpy()    \n",
    "    print(X_sim.shape, X_phy.shape, Y_sim.shape, Y_phy.shape)\n",
    "\n",
    "    # Separating Physical data to 10% and 90%\n",
    "    X_train_phy, X_test_phy, Y_train_phy, Y_test_phy = train_test_split(X_phy, Y_phy, test_size = 0.90, random_state = 0)\n",
    "    print(X_train_phy.shape, X_test_phy.shape, Y_train_phy.shape, Y_test_phy.shape)\n",
    "    X_train_sim = np.append(X_sim, X_train_phy,axis = 0)\n",
    "    Y_train_sim = np.append(Y_sim, Y_train_phy,axis = 0)\n",
    "    print(X_train_sim.shape, Y_train_sim.shape, X_test_phy.shape, Y_test_phy.shape)\n",
    "    \n",
    "    X_train = X_train_sim\n",
    "    X_test = X_test_phy\n",
    "    Y_train = Y_train_sim\n",
    "    Y_test = Y_test_phy\n",
    "    print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "    \n",
    "    scaler_X_sim = StandardScaler()\n",
    "    scaler_X_phy = StandardScaler()\n",
    "    scaler_X_sim.fit(X_sim)\n",
    "    scaler_X_phy.fit(X_phy)\n",
    "    \n",
    "    scaler_Y_sim = StandardScaler()\n",
    "    scaler_Y_phy = StandardScaler()\n",
    "    Y_sim = np.reshape(Y_sim, (len(Y_sim),1))\n",
    "    Y_phy = np.reshape(Y_phy, (len(Y_phy),1))    \n",
    "    scaler_Y_sim.fit(Y_sim)\n",
    "    scaler_Y_phy.fit(Y_phy)\n",
    "    \n",
    "    X_train = scaler_X_sim.transform(X_train)\n",
    "    X_test = scaler_X_phy.transform(X_test)\n",
    "    Y_train = np.reshape(Y_train, (len(Y_train),1))\n",
    "    Y_test = np.reshape(Y_test, (len(Y_test),1))\n",
    "    Y_train = scaler_Y_sim.transform(Y_train)\n",
    "    Y_test = scaler_Y_phy.fit_transform(Y_test)    \n",
    "    \n",
    "    ################## Data Preprocessing ######################\n",
    "    '''pca = PCA(n_components=9)\n",
    "    pca.fit(X_train)\n",
    "    X_train = pca.transform(X_train)'''\n",
    "\n",
    "    # pca = PCA(n_components=9)\n",
    "    # pca.fit(X_test)\n",
    "    # X_test = pca.transform(X_test)\n",
    "    # Put best models here using grid search\n",
    "    \n",
    "    \n",
    "    # 4. KNN\n",
    "    param_grid_knn =   {'n_neighbors': [ 6, 7, 13, 15],  \n",
    "             'weights' : ['uniform', 'distance'],\n",
    "              'p' : [1, 2, 4, 5, 7 ,10]\n",
    "             } \n",
    "    model_knn = KNeighborsRegressor()          \n",
    "    # best_knn = return_best_param(model_knn, param_grid_knn, X_train, Y_train) \n",
    "    \n",
    "    model_dt = DecisionTreeRegressor()          \n",
    "    # best_dt = return_best_param(model_dt, param_grid_dt, X_train, Y_train) \n",
    "\n",
    "    # 7. Random Forest \n",
    "    param_grid_rf =   {'n_estimators' : [50,  200],  \n",
    "              'max_depth': [5,9,15,20]\n",
    "\n",
    "             } \n",
    "    model_rf = RandomForestRegressor()          \n",
    "    # best_rf = return_best_param(model_rf, param_grid_rf, X_train, Y_train) \n",
    "    \n",
    "    # 8. Extra Trees Regressor\n",
    "    param_grid_etr =   {'n_estimators' : [50, 200],\n",
    "              'max_depth': [5,9,15,20]\n",
    "                       }\n",
    "    model_etr = ExtraTreesRegressor()          \n",
    "    # best_etr =  return_best_param(model_etr, param_grid_etr, X_train, Y_train) \n",
    "    \n",
    "    \n",
    "    # return_best_param(model_xgb, param_grid_xgb, X_train, Y_train)\n",
    "    \n",
    "    # best_models = [best_lr, best_rr, best_knn, best_gpr, best_dt, best_rf, best_etr]\n",
    "    best_models = [model_knn, model_dt, model_rf, model_etr]\n",
    "    best_models_name = [ 'best_knn', 'best_dt', 'best_rf', 'best_etr']\n",
    "    k = 0\n",
    "    \n",
    "    \n",
    "    r2_scores = []\n",
    "    mape_scores = []\n",
    "    for model in best_models:\n",
    "        model_orig = model\n",
    "        print('Running model number:', k+1, 'with Model Name: ', best_models_name[k])\n",
    "        print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "        model_orig.fit(X_train, Y_train)\n",
    "        Y_pred_fold = model_orig.predict(X_test)\n",
    "        Y_test_fold = scaler_Y_phy.inverse_transform(Y_test)\n",
    "        Y_pred_fold = scaler_Y_phy.inverse_transform(Y_pred_fold)\n",
    "\n",
    "        \n",
    "        r2_scores.append(r2_score(Y_test_fold, Y_pred_fold))\n",
    "        mape_scores.append(absolute_percentage_error(Y_test_fold, Y_pred_fold))\n",
    "        \n",
    "\n",
    "        k = k + 1  \n",
    "    return r2_scores, mape_scores\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'PS', 'runtime',\n",
      "       'power'],\n",
      "      dtype='object') Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'PS', 'runtime',\n",
      "       'power'],\n",
      "      dtype='object') 19 19\n",
      "(1365, 17) (260, 17) (1365,) (260,)\n",
      "(26, 17) (234, 17) (26,) (234,)\n",
      "(1391, 17) (1391,) (234, 17) (234,)\n",
      "(1391, 17) (234, 17) (1391,) (234,)\n",
      "Running model number: 1 with Model Name:  best_knn\n",
      "(1391, 17) (234, 17) (1391, 1) (234, 1)\n",
      "Running model number: 2 with Model Name:  best_dt\n",
      "(1391, 17) (234, 17) (1391, 1) (234, 1)\n",
      "Running model number: 3 with Model Name:  best_rf\n",
      "(1391, 17) (234, 17) (1391, 1) (234, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model number: 4 with Model Name:  best_etr\n",
      "(1391, 17) (234, 17) (1391, 1) (234, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'PS', 'runtime',\n",
      "       'power'],\n",
      "      dtype='object') Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'PS', 'runtime',\n",
      "       'power'],\n",
      "      dtype='object') 19 19\n",
      "(1365, 17) (260, 17) (1365,) (260,)\n",
      "(26, 17) (234, 17) (26,) (234,)\n",
      "(1391, 17) (1391,) (234, 17) (234,)\n",
      "(1391, 17) (234, 17) (1391,) (234,)\n",
      "Running model number: 1 with Model Name:  best_knn\n",
      "(1391, 17) (234, 17) (1391, 1) (234, 1)\n",
      "Running model number: 2 with Model Name:  best_dt\n",
      "(1391, 17) (234, 17) (1391, 1) (234, 1)\n",
      "Running model number: 3 with Model Name:  best_rf\n",
      "(1391, 17) (234, 17) (1391, 1) (234, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model number: 4 with Model Name:  best_etr\n",
      "(1391, 17) (234, 17) (1391, 1) (234, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_name         r2  mape_runtime  mape_power\n",
      "0   best_knn   0.010851      2.475787    0.743036\n",
      "1    best_dt  -0.173435      1.925371    0.633345\n",
      "2    best_rf  -0.191443      2.233268    0.660251\n",
      "3   best_etr -19.602992      5.211828    0.595247\n"
     ]
    }
   ],
   "source": [
    "dataset_name_n = 'montecarlocalcpi_physical'\n",
    "dataset_name = 'montecarlocalcpi_simulated'\n",
    "dataset_path = '\\\\ALL_CSV\\\\Dataset\\\\'\n",
    "path_for_saving_data = dataset_name\n",
    "r2_runtime, mape_runtime = process_all_montecarlo(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val = 'runtime')                       \n",
    "r2_power, mape_power = process_all_montecarlo(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val = 'power')                       \n",
    "# print(r2_runtime, r2_power)\n",
    "r2 = []\n",
    "for i in range(4):\n",
    "    r2.append(np.mean([r2_runtime[i], r2_power[i]]))\n",
    "df = pd.DataFrame(columns = ['model_name','r2', 'mape_runtime', 'mape_power'])    \n",
    "\n",
    "best_models_name = [ 'best_knn', 'best_dt', 'best_rf', 'best_etr']\n",
    "for k in range(4):\n",
    "    df = df.append({'model_name': best_models_name[k],\n",
    "                         'r2': r2[k], 'mape_runtime': mape_runtime[k][0],'mape_power': mape_power[k][0]}\n",
    "                       , ignore_index=True)   \n",
    "print(df)    \n",
    "df.to_csv('result_univariate_montecarlo' + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_mser(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val):\n",
    "    \n",
    "    ################## Data Preprocessing ######################\n",
    "    \n",
    "    df = pd.read_csv(dataset_path + dataset_name + '.csv')\n",
    "    dfn = pd.read_csv(dataset_path + dataset_name_n + '.csv')\n",
    "    encoded_data_frame, encoder_isa, encoder_mem_type = encode_text_features('encode', df\n",
    "                                                                             , encoder_isa = None, encoder_mem_type=None)\n",
    "    encoded_data_frame_n, encoder_isa_n, encoder_mem_type_n = encode_text_features('encode', dfn\n",
    "                                                                                   , encoder_isa = None, encoder_mem_type=None)\n",
    "    \n",
    "    total_data_n = encoded_data_frame_n.drop(columns = ['arch','mem-type_1','mem-type_2','mem-type_3','mem-type_4',\n",
    "                                                        'isa_1','isa_2' ,'isa_3', 'isa_4', 'bus_speed', 'num-cpu'])\n",
    "    total_data = encoded_data_frame.drop(columns = ['arch','mem-type_1','mem-type_2','mem-type_3','mem-type_4','isa_1',\n",
    "                                                    'isa_2'])\n",
    "    print(total_data.columns, total_data_n.columns, len(total_data.columns), len(total_data_n.columns))\n",
    "    total_data = total_data.fillna(0)\n",
    "    total_data_n = total_data_n.fillna(0)\n",
    " \n",
    "    X_sim = total_data.drop(columns = ['runtime', 'power']).to_numpy()\n",
    "    Y_sim = total_data[val].to_numpy()\n",
    "    X_phy = total_data_n.drop(columns = ['runtime', 'power']).to_numpy()\n",
    "    Y_phy = total_data_n[val].to_numpy()    \n",
    "    print(X_sim.shape, X_phy.shape, Y_sim.shape, Y_phy.shape)\n",
    "\n",
    "    # Separating Physical data to 10% and 90%\n",
    "    X_train_phy, X_test_phy, Y_train_phy, Y_test_phy = train_test_split(X_phy, Y_phy, test_size = 0.90, random_state = 0)\n",
    "    print(X_train_phy.shape, X_test_phy.shape, Y_train_phy.shape, Y_test_phy.shape)\n",
    "    X_train_sim = np.append(X_sim, X_train_phy,axis = 0)\n",
    "    Y_train_sim = np.append(Y_sim, Y_train_phy,axis = 0)\n",
    "    print(X_train_sim.shape, Y_train_sim.shape, X_test_phy.shape, Y_test_phy.shape)\n",
    "    \n",
    "    X_train = X_train_sim\n",
    "    X_test = X_test_phy\n",
    "    Y_train = Y_train_sim\n",
    "    Y_test = Y_test_phy\n",
    "    print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "    \n",
    "    scaler_X_sim = StandardScaler()\n",
    "    scaler_X_phy = StandardScaler()\n",
    "    scaler_X_sim.fit(X_sim)\n",
    "    scaler_X_phy.fit(X_phy)\n",
    "    \n",
    "    scaler_Y_sim = StandardScaler()\n",
    "    scaler_Y_phy = StandardScaler()\n",
    "    Y_sim = np.reshape(Y_sim, (len(Y_sim),1))\n",
    "    Y_phy = np.reshape(Y_phy, (len(Y_phy),1))    \n",
    "    scaler_Y_sim.fit(Y_sim)\n",
    "    scaler_Y_phy.fit(Y_phy)\n",
    "    \n",
    "    X_train = scaler_X_sim.transform(X_train)\n",
    "    X_test = scaler_X_phy.transform(X_test)\n",
    "    Y_train = np.reshape(Y_train, (len(Y_train),1))\n",
    "    Y_test = np.reshape(Y_test, (len(Y_test),1))\n",
    "    Y_train = scaler_Y_sim.transform(Y_train)\n",
    "    Y_test = scaler_Y_phy.fit_transform(Y_test)    \n",
    "    \n",
    "    ################## Data Preprocessing ######################\n",
    "    '''pca = PCA(n_components=9)\n",
    "    pca.fit(X_train)\n",
    "    X_train = pca.transform(X_train)'''\n",
    "\n",
    "    # pca = PCA(n_components=9)\n",
    "    # pca.fit(X_test)\n",
    "    # X_test = pca.transform(X_test)\n",
    "    # Put best models here using grid search\n",
    "    \n",
    "    \n",
    "    # 4. KNN\n",
    "    param_grid_knn =   {'n_neighbors': [ 6, 7, 13, 15],  \n",
    "             'weights' : ['uniform', 'distance'],\n",
    "              'p' : [1, 2, 4, 5, 7 ,10]\n",
    "             } \n",
    "    model_knn = KNeighborsRegressor()          \n",
    "    # best_knn = return_best_param(model_knn, param_grid_knn, X_train, Y_train) \n",
    "    \n",
    "    model_dt = DecisionTreeRegressor()          \n",
    "    # best_dt = return_best_param(model_dt, param_grid_dt, X_train, Y_train) \n",
    "\n",
    "    # 7. Random Forest \n",
    "    param_grid_rf =   {'n_estimators' : [50,  200],  \n",
    "              'max_depth': [5,9,15,20]\n",
    "\n",
    "             } \n",
    "    model_rf = RandomForestRegressor()          \n",
    "    # best_rf = return_best_param(model_rf, param_grid_rf, X_train, Y_train) \n",
    "    \n",
    "    # 8. Extra Trees Regressor\n",
    "    param_grid_etr =   {'n_estimators' : [50, 200],\n",
    "              'max_depth': [5,9,15,20]\n",
    "                       }\n",
    "    model_etr = ExtraTreesRegressor()          \n",
    "    # best_etr =  return_best_param(model_etr, param_grid_etr, X_train, Y_train) \n",
    "    \n",
    "    \n",
    "    # return_best_param(model_xgb, param_grid_xgb, X_train, Y_train)\n",
    "    \n",
    "    # best_models = [best_lr, best_rr, best_knn, best_gpr, best_dt, best_rf, best_etr]\n",
    "    best_models = [model_knn, model_dt, model_rf, model_etr]\n",
    "    best_models_name = [ 'best_knn', 'best_dt', 'best_rf', 'best_etr']\n",
    "    k = 0\n",
    "    \n",
    "    \n",
    "    r2_scores = []\n",
    "    mape_scores = []\n",
    "    for model in best_models:\n",
    "        model_orig = model\n",
    "        print('Running model number:', k+1, 'with Model Name: ', best_models_name[k])\n",
    "        print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "        model_orig.fit(X_train, Y_train)\n",
    "        Y_pred_fold = model_orig.predict(X_test)\n",
    "        Y_test_fold = scaler_Y_phy.inverse_transform(Y_test)\n",
    "        Y_pred_fold = scaler_Y_phy.inverse_transform(Y_pred_fold)\n",
    "\n",
    "        \n",
    "        r2_scores.append(r2_score(Y_test_fold, Y_pred_fold))\n",
    "        mape_scores.append(absolute_percentage_error(Y_test_fold, Y_pred_fold))\n",
    "        \n",
    "\n",
    "        k = k + 1  \n",
    "    return r2_scores, mape_scores\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') 18 18\n",
      "(430, 16) (52, 16) (430,) (52,)\n",
      "(5, 16) (47, 16) (5,) (47,)\n",
      "(435, 16) (435,) (47, 16) (47,)\n",
      "(435, 16) (47, 16) (435,) (47,)\n",
      "Running model number: 1 with Model Name:  best_knn\n",
      "(435, 16) (47, 16) (435, 1) (47, 1)\n",
      "Running model number: 2 with Model Name:  best_dt\n",
      "(435, 16) (47, 16) (435, 1) (47, 1)\n",
      "Running model number: 3 with Model Name:  best_rf\n",
      "(435, 16) (47, 16) (435, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model number: 4 with Model Name:  best_etr\n",
      "(435, 16) (47, 16) (435, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') 18 18\n",
      "(430, 16) (52, 16) (430,) (52,)\n",
      "(5, 16) (47, 16) (5,) (47,)\n",
      "(435, 16) (435,) (47, 16) (47,)\n",
      "(435, 16) (47, 16) (435,) (47,)\n",
      "Running model number: 1 with Model Name:  best_knn\n",
      "(435, 16) (47, 16) (435, 1) (47, 1)\n",
      "Running model number: 2 with Model Name:  best_dt\n",
      "(435, 16) (47, 16) (435, 1) (47, 1)\n",
      "Running model number: 3 with Model Name:  best_rf\n",
      "(435, 16) (47, 16) (435, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model number: 4 with Model Name:  best_etr\n",
      "(435, 16) (47, 16) (435, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_name        r2  mape_runtime  mape_power\n",
      "0   best_knn -0.127201      0.278283    0.717318\n",
      "1    best_dt  0.269796      0.237772    0.657332\n",
      "2    best_rf  0.162004      0.203831    0.708848\n",
      "3   best_etr  0.388831      0.226810    0.519449\n"
     ]
    }
   ],
   "source": [
    "dataset_name_n = 'mser_physical'\n",
    "dataset_name = 'mser_simulated'\n",
    "dataset_path = '\\\\ALL_CSV\\\\Dataset\\\\'\n",
    "path_for_saving_data = dataset_name\n",
    "r2_runtime, mape_runtime = process_all_mser(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val = 'runtime')                       \n",
    "r2_power, mape_power = process_all_mser(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val = 'power')                       \n",
    "# print(r2_runtime, r2_power)\n",
    "r2 = []\n",
    "for i in range(4):\n",
    "    r2.append(np.mean([r2_runtime[i], r2_power[i]]))\n",
    "df = pd.DataFrame(columns = ['model_name','r2', 'mape_runtime', 'mape_power'])    \n",
    "\n",
    "best_models_name = [ 'best_knn', 'best_dt', 'best_rf', 'best_etr']\n",
    "for k in range(4):\n",
    "    df = df.append({'model_name': best_models_name[k],\n",
    "                         'r2': r2[k], 'mape_runtime': mape_runtime[k][0],'mape_power': mape_power[k][0]}\n",
    "                       , ignore_index=True)   \n",
    "print(df)    \n",
    "df.to_csv('result_univariate_mser' + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_stitch(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val):\n",
    "    \n",
    "    ################## Data Preprocessing ######################\n",
    "    \n",
    "    df = pd.read_csv(dataset_path + dataset_name + '.csv')\n",
    "    dfn = pd.read_csv(dataset_path + dataset_name_n + '.csv')\n",
    "    encoded_data_frame, encoder_isa, encoder_mem_type = encode_text_features('encode', df\n",
    "                                                                             , encoder_isa = None, encoder_mem_type=None)\n",
    "    encoded_data_frame_n, encoder_isa_n, encoder_mem_type_n = encode_text_features('encode', dfn\n",
    "                                                                                   , encoder_isa = None, encoder_mem_type=None)\n",
    "    \n",
    "    total_data_n = encoded_data_frame_n.drop(columns = ['arch','mem-type_1','mem-type_2','mem-type_3','mem-type_4',\n",
    "                                                        'isa_1','isa_2' ,'isa_3', 'isa_4', 'bus_speed', 'num-cpu'])\n",
    "    total_data = encoded_data_frame.drop(columns = ['arch','mem-type_1','mem-type_2','mem-type_3','mem-type_4','isa_1',\n",
    "                                                    'isa_2'])\n",
    "    print(total_data.columns, total_data_n.columns, len(total_data.columns), len(total_data_n.columns))\n",
    "    total_data = total_data.fillna(0)\n",
    "    total_data_n = total_data_n.fillna(0)\n",
    " \n",
    "    X_sim = total_data.drop(columns = ['runtime', 'power']).to_numpy()\n",
    "    Y_sim = total_data[val].to_numpy()\n",
    "    X_phy = total_data_n.drop(columns = ['runtime', 'power']).to_numpy()\n",
    "    Y_phy = total_data_n[val].to_numpy()    \n",
    "    print(X_sim.shape, X_phy.shape, Y_sim.shape, Y_phy.shape)\n",
    "\n",
    "    # Separating Physical data to 10% and 90%\n",
    "    X_train_phy, X_test_phy, Y_train_phy, Y_test_phy = train_test_split(X_phy, Y_phy, test_size = 0.90, random_state = 0)\n",
    "    print(X_train_phy.shape, X_test_phy.shape, Y_train_phy.shape, Y_test_phy.shape)\n",
    "    X_train_sim = np.append(X_sim, X_train_phy,axis = 0)\n",
    "    Y_train_sim = np.append(Y_sim, Y_train_phy,axis = 0)\n",
    "    print(X_train_sim.shape, Y_train_sim.shape, X_test_phy.shape, Y_test_phy.shape)\n",
    "    \n",
    "    X_train = X_train_sim\n",
    "    X_test = X_test_phy\n",
    "    Y_train = Y_train_sim\n",
    "    Y_test = Y_test_phy\n",
    "    print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "    \n",
    "    scaler_X_sim = StandardScaler()\n",
    "    scaler_X_phy = StandardScaler()\n",
    "    scaler_X_sim.fit(X_sim)\n",
    "    scaler_X_phy.fit(X_phy)\n",
    "    \n",
    "    scaler_Y_sim = StandardScaler()\n",
    "    scaler_Y_phy = StandardScaler()\n",
    "    Y_sim = np.reshape(Y_sim, (len(Y_sim),1))\n",
    "    Y_phy = np.reshape(Y_phy, (len(Y_phy),1))    \n",
    "    scaler_Y_sim.fit(Y_sim)\n",
    "    scaler_Y_phy.fit(Y_phy)\n",
    "    \n",
    "    X_train = scaler_X_sim.transform(X_train)\n",
    "    X_test = scaler_X_phy.transform(X_test)\n",
    "    Y_train = np.reshape(Y_train, (len(Y_train),1))\n",
    "    Y_test = np.reshape(Y_test, (len(Y_test),1))\n",
    "    Y_train = scaler_Y_sim.transform(Y_train)\n",
    "    Y_test = scaler_Y_phy.fit_transform(Y_test)    \n",
    "    \n",
    "    ################## Data Preprocessing ######################\n",
    "    '''pca = PCA(n_components=9)\n",
    "    pca.fit(X_train)\n",
    "    X_train = pca.transform(X_train)'''\n",
    "\n",
    "    # pca = PCA(n_components=9)\n",
    "    # pca.fit(X_test)\n",
    "    # X_test = pca.transform(X_test)\n",
    "    # Put best models here using grid search\n",
    "    \n",
    "    \n",
    "    # 4. KNN\n",
    "    param_grid_knn =   {'n_neighbors': [ 6, 7, 13, 15],  \n",
    "             'weights' : ['uniform', 'distance'],\n",
    "              'p' : [1, 2, 4, 5, 7 ,10]\n",
    "             } \n",
    "    model_knn = KNeighborsRegressor()          \n",
    "    # best_knn = return_best_param(model_knn, param_grid_knn, X_train, Y_train) \n",
    "    \n",
    "    model_dt = DecisionTreeRegressor()          \n",
    "    # best_dt = return_best_param(model_dt, param_grid_dt, X_train, Y_train) \n",
    "\n",
    "    # 7. Random Forest \n",
    "    param_grid_rf =   {'n_estimators' : [50,  200],  \n",
    "              'max_depth': [5,9,15,20]\n",
    "\n",
    "             } \n",
    "    model_rf = RandomForestRegressor()          \n",
    "    # best_rf = return_best_param(model_rf, param_grid_rf, X_train, Y_train) \n",
    "    \n",
    "    # 8. Extra Trees Regressor\n",
    "    param_grid_etr =   {'n_estimators' : [50, 200],\n",
    "              'max_depth': [5,9,15,20]\n",
    "                       }\n",
    "    model_etr = ExtraTreesRegressor()          \n",
    "    # best_etr =  return_best_param(model_etr, param_grid_etr, X_train, Y_train) \n",
    "    \n",
    "    \n",
    "    # return_best_param(model_xgb, param_grid_xgb, X_train, Y_train)\n",
    "    \n",
    "    # best_models = [best_lr, best_rr, best_knn, best_gpr, best_dt, best_rf, best_etr]\n",
    "    best_models = [model_knn, model_dt, model_rf, model_etr]\n",
    "    best_models_name = [ 'best_knn', 'best_dt', 'best_rf', 'best_etr']\n",
    "    k = 0\n",
    "    \n",
    "    \n",
    "    r2_scores = []\n",
    "    mape_scores = []\n",
    "    for model in best_models:\n",
    "        model_orig = model\n",
    "        print('Running model number:', k+1, 'with Model Name: ', best_models_name[k])\n",
    "        print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "        model_orig.fit(X_train, Y_train)\n",
    "        Y_pred_fold = model_orig.predict(X_test)\n",
    "        Y_test_fold = scaler_Y_phy.inverse_transform(Y_test)\n",
    "        Y_pred_fold = scaler_Y_phy.inverse_transform(Y_pred_fold)\n",
    "\n",
    "        \n",
    "        r2_scores.append(r2_score(Y_test_fold, Y_pred_fold))\n",
    "        mape_scores.append(absolute_percentage_error(Y_test_fold, Y_pred_fold))\n",
    "        \n",
    "\n",
    "        k = k + 1  \n",
    "    return r2_scores, mape_scores\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') 18 18\n",
      "(425, 16) (52, 16) (425,) (52,)\n",
      "(5, 16) (47, 16) (5,) (47,)\n",
      "(430, 16) (430,) (47, 16) (47,)\n",
      "(430, 16) (47, 16) (430,) (47,)\n",
      "Running model number: 1 with Model Name:  best_knn\n",
      "(430, 16) (47, 16) (430, 1) (47, 1)\n",
      "Running model number: 2 with Model Name:  best_dt\n",
      "(430, 16) (47, 16) (430, 1) (47, 1)\n",
      "Running model number: 3 with Model Name:  best_rf\n",
      "(430, 16) (47, 16) (430, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model number: 4 with Model Name:  best_etr\n",
      "(430, 16) (47, 16) (430, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') Index(['cpu-clock', 'l1d_assoc', 'l1d_cache_lines', 'l1d_shared_by_threads',\n",
      "       'l1d_size', 'l2_assoc', 'l2_cache_lines', 'l2_shared_by_threads',\n",
      "       'l2_size', 'l3_assoc', 'l3_cache_lines', 'l3_shared_by_threads',\n",
      "       'l3_size', 'mem-size', 'mem_clock', 'num-cpus', 'runtime', 'power'],\n",
      "      dtype='object') 18 18\n",
      "(425, 16) (52, 16) (425,) (52,)\n",
      "(5, 16) (47, 16) (5,) (47,)\n",
      "(430, 16) (430,) (47, 16) (47,)\n",
      "(430, 16) (47, 16) (430,) (47,)\n",
      "Running model number: 1 with Model Name:  best_knn\n",
      "(430, 16) (47, 16) (430, 1) (47, 1)\n",
      "Running model number: 2 with Model Name:  best_dt\n",
      "(430, 16) (47, 16) (430, 1) (47, 1)\n",
      "Running model number: 3 with Model Name:  best_rf\n",
      "(430, 16) (47, 16) (430, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model number: 4 with Model Name:  best_etr\n",
      "(430, 16) (47, 16) (430, 1) (47, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_name        r2  mape_runtime  mape_power\n",
      "0   best_knn -0.055239      0.162916    0.590057\n",
      "1    best_dt  0.289099      0.168052    0.469719\n",
      "2    best_rf  0.445561      0.131533    0.422779\n",
      "3   best_etr  0.262938      0.141010    0.438473\n"
     ]
    }
   ],
   "source": [
    "dataset_name_n = 'stitch_physical'\n",
    "dataset_name = 'stitch_simulated'\n",
    "dataset_path = '\\\\ALL_CSV\\\\Dataset\\\\'\n",
    "path_for_saving_data = dataset_name\n",
    "r2_runtime, mape_runtime = process_all_stitch(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val = 'runtime')                       \n",
    "r2_power, mape_power = process_all_stitch(dataset_path, dataset_name,dataset_name_n,path_for_saving_data, val = 'power')                       \n",
    "# print(r2_runtime, r2_power)\n",
    "r2 = []\n",
    "for i in range(4):\n",
    "    r2.append(np.mean([r2_runtime[i], r2_power[i]]))\n",
    "df = pd.DataFrame(columns = ['model_name','r2', 'mape_runtime', 'mape_power'])    \n",
    "\n",
    "best_models_name = [ 'best_knn', 'best_dt', 'best_rf', 'best_etr']\n",
    "for k in range(4):\n",
    "    df = df.append({'model_name': best_models_name[k],\n",
    "                         'r2': r2[k], 'mape_runtime': mape_runtime[k][0],'mape_power': mape_power[k][0]}\n",
    "                       , ignore_index=True)   \n",
    "print(df)    \n",
    "df.to_csv('result_univariate_stitch' + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "All_Models_Sim_to_PHY.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
